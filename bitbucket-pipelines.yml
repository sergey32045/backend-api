# This is an example Starter pipeline configuration
# Use a skeleton to build, test and deploy using manual and parallel steps
# -----
# You can specify a custom docker image from Docker Hub as your build environment.

image: node:16
definitions:
  services:
    docker:
      memory: 4096
options:
  docker: true
  size: 2x
pipelines:
  branches:
    master:
      - parallel:
        - step:
            name: "Install dependencies"
            caches:
                - node
            script:
                - cd api && yarn install
        - step:
            name: "Linters"
            caches:
              - node
            script:
              - cd api && yarn format:check
      - step:
          #python image with aws-cli installed
          name: "Docker build images and push to registry"
          image: python:3.7.4-alpine3.10
          services:
            - docker
          size: 2x
          script:
            - pip3 install awscli
            - IMAGE="${AWS_REGISTRY_URL}"
            - TAG=${BITBUCKET_BRANCH:$BITBUCKET_TAG}
            - aws configure set aws_access_key_id "${AWS_ACCESS_KEY_ID}"
            - aws configure set aws_secret_access_key "${AWS_SECRET_ACCESS_KEY}"
            - eval $(aws ecr get-login --no-include-email --region ${AWS_DEFAULT_REGION} | sed 's;https://;;g')
            - docker build --target production -t $IMAGE:$TAG . -f ./docker/api/Dockerfile
            - docker push $IMAGE:$TAG
      - step:
          name: "Deploy to prod"
          script:
            - pipe: atlassian/aws-ecs-deploy:1.6.2
              variables:
                AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
                AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
                AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
                CLUSTER_NAME: ${AWS_ECS_CLUSTER}
                SERVICE_NAME: ${AWS_ECS_SERVICE}
                TASK_DEFINITION: './deploy/task-definition.json'
                FORCE_NEW_DEPLOYMENT: 'true'
