# This is an example Starter pipeline configuration
# Use a skeleton to build, test and deploy using manual and parallel steps
# -----
# You can specify a custom docker image from Docker Hub as your build environment.

image: node:16
definitions:
  services:
    docker:
      memory: 4096
options:
  docker: true
  size: 2x
pipelines:
  branches:
    master:
      - parallel:
        - step:
            name: "Install dependencies"
            caches:
                - node
            script:
                - cd api && yarn install
        - step:
            #python image with aws-cli installed
            name: "Docker build images and push to registry"
            image: python:3.7.4-alpine3.10
            services:
              - docker
            size: 2x
            script:
              - pip3 install awscli
              - IMAGE="${AWS_REGISTRY_URL}"
              - TAG=${BITBUCKET_BRANCH:$BITBUCKET_TAG}
              - aws configure set aws_access_key_id "${AWS_ACCESS_KEY_ID}"
              - aws configure set aws_secret_access_key "${AWS_SECRET_ACCESS_KEY}"
              - eval $(aws ecr get-login --no-include-email --region eu-central-1 | sed 's;https://;;g')
              - docker build -t $IMAGE:$TAG . -f ./docker/api/Dockerfile
              - docker push $IMAGE:$TAG
      - step:
          name: "Deploy to prod"
          script:
            - pipe: atlassian/aws-ecs-deploy:1.6.2
              variables:
                AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID} # Optional if already defined in the context.
                AWS_SECRET_ACCESS_KEY: ${AWS_ACCESS_KEY_ID} # Optional if already defined in the context.
                AWS_DEFAULT_REGION: eu-central-1 # Optional if already defined in the context.
                CLUSTER_NAME: 'super-cluster-4'
                SERVICE_NAME: 'interviewboom-service'
#                TASK_DEFINITION: './deploy/task-definition.json' # Optional
                FORCE_NEW_DEPLOYMENT: 'true' # Optional

